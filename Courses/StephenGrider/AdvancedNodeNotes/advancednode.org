#+TITLE: Stephen Grider Advanced Node Course Notes
#+AUTHOR: @tomcatfever
#+CATEGORY: Courses 
#+STARTUP: overview
#+STARTUP: indent 
#+SEQ_TODO: TODO CURRENT SOMEDAY | DONE CANCEL
* Advanced Node Course
** DONE Part One: The Internals of Node 
CLOSED: [2018-05-22 Tue 11:20]
*** DONE Configure local project for examples with eslint and babel properly
CLOSED: [2018-05-21 Mon 12:05]
*** DONE Connect Visual Studio Code with eslint
CLOSED: [2018-05-21 Mon 12:07]
*** DONE Configure Spacemacs React layer
CLOSED: [2018-05-21 Mon 12:05]
*** DONE Advance Node Course: Part one screenshots
CLOSED: [2018-05-21 Mon 12:32]
** DONE Part Two: Enhancing Node Performance 
CLOSED: [2018-05-29 Tue 08:13]
*** Overview
The agenda talks about performance, children, clustering, and workers.  Will these lectures build on an understanding of the Event Loop and Thread Pool?
** CURRENT Part Three: Project Setup 
*** Overview 
Setting up a MongoDB project

** Part Four: Data Caching with Redis 
*** Overview
Continues MongoDB project using Redis, understanding cashes, promises, models
** Part Five: Automated Headless Browser Testing 
*** Overview
Long section.  Automates project testing with Flow, Jest, Chromium, and Puppeteer.  Covers concepts like DRY testing, the wait keyword, and advanced testing helpers.
** Part Six: Wiring Up Continuous Integration 
   - 15 Lectures 
   - 01:19:36 time
*** Overview 
The example project introduces continuous integration concepts, YAML files, and Travis.
** Part Seven: Scalable Image/File Upload 
   - 30 Lectures 
   - 02:20:33 time
*** Overview 
The final section covers image handling, converting large image files for AWS, and wiring up AWS Flow.
** TODO Clean Up
*** DONE Outline all the parts
CLOSED: [2018-05-22 Tue 13:33]
*** DONE Review PM2 Documentation
CLOSED: [2018-05-29 Tue 08:14]
*** TODO Resize and insert screen-shots
*** DONE Connect Spacemacs flycheck with local eslint directory 
CLOSED: [2018-05-29 Tue 08:14]
Resolved using react layer.
*** TODO Outside of course: Set up orgmode calendar
*** SOMEDAY Craft this into blog post
* Part One: The Internals of Node
** NodeJS, V8, and libuv
*First Takeaways*
- V8 Engine allows us to execute JS code outside of the browser.
- Libuv is a C++ project that give access to the file system, networking,
  and some parts of concurrency.
- NodeJS provides a javascript interface and API that allows us to use V8 
  and libuv.
- All the javascript code is in the lib directory on node's github page.
- The c++ code is in the src directory.

:ImageBasicNodeParts:
#+CAPTION: This is an image of the basic part of node.
[[./img/node-parts-simple.png]]
:END:

:ImageCryptoPath:
#+CAPTION: Introduces http fs crypto and path, lecture 9636088
[[./img/node-parts-simple-2.png]]
:END:

:ImageProcessBinding:
#+CAPTION: The process.binding() function connects a node function to V8 engine
[[./img/node-process.binding.png]]
:END:

- Once again, in NodeJS:
  - V8 is used to interpret and execute Javascript code, while
  - libuv is used for accessing the filesystem and some aspects of concurrency.

** Event Loop And Threads
*** What Are Threads?
:ImageOsxActivityMonitor:
#+CAPTION: This shows the OSX activity monitor.
[[./img/activity-monitor-threads.png]]
:END:
:ImageScheduling:
#+CAPTION: Scheduling is how a computer decides which thread to process.
[[./img/thread-scheduling.png]]
:END:
:ImageMultiCoreThreading:
#+CAPTION: To process more thread, engineers can schedule using more CPU cores, aka multi-threading or hyper-threading.
[[./img/thread-cpu-core.png]]
:END:
*** Introducing The Event Loop
*Next Takeaways*
  - Understanding the event loop will enables you to understand performance issues in NodeJS.
  - The event loop is difficult to understand.

/The image and pseudo-code examples will illustrate./

:ImageThreadEventLoop:
#+CAPTION: This visualizes how the 'event loop' handles threading in a NodeJS program.
[[./img/node-thread-loop.png]]
:END:

:PseudoCodeExample:
#+BEGIN_SRC js
// Node myFile JS
// These arrays simulate book-keeping operations.
const pendingTimers = [];
const pendingOSTasks = [];
const pendingOperations = [];

// New timers, tasks, operaitons are recorded from myFile running
myFile.runContents();

// Helper function - While loop continues for another tick.
// This describes the three pending checks NodeJS makes. 
function shouldContinue() {
  // Check One: Any pending setTimeout, setInterval, or setImmediate?
  // Check Two: Any pending OS tasks? (Like a server listening on a port)
  // Check Three: Any pending long running operations? (Like fs module) 
  return pendingTimers.length || pendingOSTasks.length || pendingOperations.length
}

// Remember while loops continue while(bool=true). In this example,
// the entire body executes in one 'tick' (is one iteration of Event Loop).

while(shouldContinue()) {
 // 1) Node looks at pendingTimers and sees if any functions are ready to be called.
 //    This involves the built in NodeJS functions setTimeout, setInterval.

 // 2) Node looks at pendingOSTasks and pendingOperations and calls relevant callbacks

 // 3) Pause execution. Continue when...
 //    - a new pendingOSTasks is done,
 //    - a new pendingOperation is done, or
 //    - a timer is about to complete. 

 // 4) Look at pendingTimers. Call any setImmediate.

 // 5) Handle any 'close' events.
}
// exit back to terminal
#+END_SRC
:END:

*** Event Loop: Single Threaded?
/In general, the NodeJS:/
*Event Loop* => Single Threaded

/However, some of NodeJS:/
*Framework/Std Lib => *Not* Single Threaded
**** Thread Pool Code Example
[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/?start=963611215][Course Link: Diagram of how node is actually threaded]]
Brief
Basically libuv creates a thread pool of calculation intensive methods like pbkdf2 which run separately.  NodeJS defaults to 4 threads as shown in the diagram. As a result the code example returns this result:
:threads:
#+BEGIN_SRC sh
$ node threads.js
2: 1047
1: 1052
#+END_SRC
:END:

Four calls are allocated to each of the default four threads:

:defaultThreads:
#+BEGIN_SRC sh
$ node threads.js
2: 2102
1: 2108
3: 2108
4: 2114
#+END_SRC
:END:

Notice that it takes a second longer?  Try with five calls:

:fiveThreads:
#+BEGIN_SRC sh
node threads.js
3: 2115
4: 2122
2: 2127
1: 2140
5: 3205
#+END_SRC
:END:

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/?start=9636118150][Course Link: How node threads use CPU cores]]
A standard Macbook has two CPU cores.

/insert How node threads use CPU cores screenshot/

The CPU has access to multi-threading.  Therefore, each call is assigned to a thread. And then each thread concurrently resolves the calls. Finally the fifth call is assigned to a thread and resolved by the CPU.

The ~process.env~ method ~UV_THREADPOOL_SIZE~ controls the NodeJS thread pool.

#+BEGIN_SRC js
process.env.UV_THREADPOOL_SIZE = 2;
// ... rest of threads.js example
#+END_SRC

Result from running threads script with two threads and four calls:
:twoThreads:
#+BEGIN_SRC sh
$ node threads.js
2: 1069
1: 1074
3: 2141
4: 2153
5: 3181
#+END_SRC

:END:

To further test this I tried seeing the result of the following:

*1st* /Twelve calls with FOUR threads, two cores:/
:FOUR:
#+BEGIN_SRC sh
node threads.js
1: 2089
4: 2121
2: 2141
3: 2152
6: 4236
7: 4242
9: 4268
8: 4346
10: 5810
11: 5868
12 5883
#+END_SRC
:END:

*2nd* /Twelve calls with SIX threads, two cores:/
:SIX:
#+BEGIN_SRC sh
node threads.js
3: 3152
1: 3157
6: 3164
2: 3188
7: 3196
4: 3209
9: 6012
8: 6026
10: 6030
11: 6036
12 6036
#+END_SRC
:END:

**** [[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646726?start=0][Thread Pool Faq Lesson]] 
/Insert image: ThreadPool FAQ/
*** Pending OS Tasks
This code benchmarks how the asyncronous library https handles sending a response call to google.com.  Then prints it to the NodeJS REPL.

:HttpsFirstExample:
#+BEGIN_SRC js
const https = require('https');
const start = Date.now();

function doRequest() {
    https.request('https://www.google.com', res => {
            res.on('data', () => {});
            res.on('end', () => {
                console.log(Date.now() - start);
            });
        })
        .end();
}

doRequest();
#+End_SRC
:END:

This return a response of seconds to the NodeJS console. What is returned when this function is called more than once?

:Call5Times:
#+BEGIN_SRC sh
node async.js
445
448
561
562
563
563
#+END_SRC
:end:

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646730?start=100][Course Link: What happens when running ascync.js example 5x]]
*Summary*
NodeJS delegates ascync operations to the OSAscyncHelpers. *Again*, everything happens in the ThreadPool 
** Async FAQ & Review 

| Question               | Answer                           |
|------------------------+----------------------------------|
| What functions in node | Almost everything around         |
| std library use OS's   | networking for all OS's.         |
| async features?        | Some other stuff is OS specific. |
|                        |                                  |
| How does this OS       | Task using the underlying OS     |
| async stuff fit in     | are reflected in our             |
| Event Loop?            | 'pendingOSTasks' array.          |

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646734?start=110][Course Link: A summary diagram]]

:ImageSummaryDiagram:
/insert screenshot of summary/
:END:
** Code Example - Crazy Behavior
*Interview Question:*
/What order will the console logs appear from this code example?/

:MultitaskJS:
#+BEGIN_SRC js
process.env.UV_THREADPOOL_SIZE = 4;

const https = require('https');
const crypto = require('crypto');
const fs = require('fs');

const start = Date.now();

function doHash() {
  crypto.pbkdf2('a', 'b', 100000, 512, 'sha512', () => {
    console.log('Hash:', Date.now() - start);
  });
}

function doRequest() {
  https
    .request('https://www.google.com', (res) => {
      res.on('data', () => {});
      res.on('end', () => {
        console.log('Request:', Date.now() - start);
      });
    })
    .end();
}

// Make a request to google.com
doRequest();

// Get all the contents of multitask.js file
fs.readFile('multitask.js', 'utf8', () => {
  console.log('FS:', Date.now() - start);
});

// Call pbkdf2 Hash eight times
doHash();
doHash();
doHash();
doHash();
doHash();
doHash();
doHash();
doHash();
#+END_SRC
:END:

I guessed FS would run first. My reasoning is that it is a local OS operation which is resolved before async calls.  And the Hash operation has a 512 millisecond timeout.  Here is the result.

:HashFourTimes:
#+BEGIN_SRC sh
node multitask.js
FS: 30
Request: 303
Hash: 2152
Hash: 2161
Hash: 2185
Hash: 2197
#+END_SRC
:END:

While, my intuition was correct something interesting happened with eight calls to Hash.

:HashEightTimes:
#+BEGIN_SRC sh
node multitask.js
Request: 339
Hash: 3237
Hash: 3252
Hash: 3289
FS: 3305
Hash: 3335
Hash: 3342
Hash: 3360
Hash: 4381
Hash: 4395
#+END_SRC 
:END:

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646746?start=44][Course Link: Unexpected Loop Events Explain FS Delay]]

Basically, FS and pbkdf2 make use of the ThreadPool.  Http uses the OS System Helper.

/Insert Image: FsHashBehavior/

To further illustrate, here is the output with a ThreadPool size of 1.

:ThreadPoolOne:
#+BEGIN_SRC sh
node multitask.js
Request: 312
Hash: 1090
Hash: 2139
Hash: 3173
Hash: 4207
Hash: 5263
Hash: 6314
Hash: 7376
Hash: 8408
FS: 8408
#+END_SRC
:END:
* Part Two: Enhancing Node Performance  
** Overview
The agenda talks about performance, children, clustering, and workers.  Will these lectures build on an understanding of the Event Loop and Thread Pool?
/Insert Image: ClusterVsWorkModes/
~Cluster Mode~ is *Recommended*
~Worker Threads~ are *Experimental*

*Express Example*
This section uses a sample express app with an entry point of index.js.
Nodemon isn't used.  It does not work well with clustering.

:IndexjsStarter:
#+BEGIN_SRC js
const express = require('express');

const app = express();

app.get('/', (req, res) => {
  res.send('Hi there');
});

app.listen(3000);
#+END_SRC
:END:
** Cluster Mode
*** Single Thread Problems
/Req/ *===>* /NODE SERVER/ *===>* /Res/
This usually works well.  But what if something takes up all the resources?
This while loop is added to the express app to demonstrate:

:doWorkfunction:
#+BEGIN_SRC js
function doWork(duration) {
  const start = Date.now();
  while (Date.now() - start < duration) {

  }
}
#+END_SRC
:END:

Now the app takes five seconds to render.
*** Clustering Theory
:LOGBOOK:
CLOCK: [2018-05-24 Thu 15:59]--[2018-05-24 Thu 16:12] =>  0:13
CLOCK: [2018-05-24 Thu 15:44]--[2018-05-24 Thu 15:50] =>  0:06
:END:

/Insert Image: Clustering Diagram/

Each tread is running a node server instance on one computer.  It is up to these instances to process request, access the database, authenticate, or whatever else a node server does.

The cluster manager can start or stop instances, send them data, and other administrative tasks.

/Insert Image: NodeUsingClustering/

The cluster manager runs like any other NodeJS function (pbkdf2, crypto, etc).

When you run cluster.fork(), Node initiates another 'Worker Instance'.

*** Add clustering to Express App example 
:LOGBOOK:
CLOCK: [2018-05-24 Thu 19:50]--[2018-05-24 Thu 20:31] =>  0:41
CLOCK: [2018-05-24 Thu 16:12]--[2018-05-24 Thu 16:27] =>  0:15
:END:

This section starts by adding cluster to the app and a test console log which returns ~true~.  The cluster manager is set to true, for all the worker instances the ~isMaster~ flag is ~false~.

#+NAME: Console logging isManager.
#+BEGIN_SRC js
const cluster = require('cluster');

console.log(cluster.isMaster);
#+END_SRC

#+NAME: Updating code example with cluster using isMaster and ~if...else~ conditional.
#+BEGIN_SRC js
const cluster = require('cluster');

if(cluster.isManager) {
  cluster.fork();
} else {
  const express = require('express');
  const app = express();

  function doWork(duration) {
    const start = Date.now();
    while(Date.now() - start < duration) {
      
    }
  }

  app.get('/', (req, res) => {
    doWork(5000);
    res.send('Hi there');
  });

  app.listen(3000);
}
#+END_SRC

#+NAME: Using clustering to make a faster loading route.
#+BEGIN_SRC js
  // First add four calls to fork. This allows requests to `/fast`
  // to resolve indepentant of the /home on isManager.
  ...
  cluster.fork();
  cluster.fork();
  cluster.fork();
  cluster.fork();
  ...

  // Now set a new route to /fast which will omit the
  // doWork function. doWork is only initiated if isManager
  // test resolves `bool=true`.
  app.get('/fast', (req, res) => {
    res.send('This was fast!');
  });
#+END_SRC

*** Clustering: Benchmark Servers
:LOGBOOK:
CLOCK: [2018-05-25 Fri 12:21]--[2018-05-25 Fri 13:01] =>  0:40
CLOCK: [2018-05-25 Fri 12:12]--[2018-05-25 Fri 12:20] =>  0:08
CLOCK: [2018-05-24 Thu 20:25]--[2018-05-24 Thu 20:42] =>  0:17
:END:

Use Apache Benchmark to benchmark requests
#+NAME: Example Of Apache Bench On OSX
#+BEGIN_SRC sh
ab -c 10 -n 50 http://localhost:3000/
#+END_SRC

#+NAME: Benchmark Refactor
#+BEGIN_SRC js
// Set one thread
process.env.UV_THREADPOOL_SIZE = 1;
const cluster = require('cluster');

if(cluster.isManager) {
  // Set one child cluster
  cluster.fork();
} else {
  const express = require('express');
  const crypto = require('crypto');
  const app = express();

  app.get('/', (req, res) => {
    // use pbkdf2 to benchmark request
    crypto.pbkdf2('a', 'b', 100000, 512, 'sha512', () => {
      res.send('Hi there');
    });
  });

  app.get('/fast', (req, res) => {
    res.send('This was fast!');
  });

  app.listen(3000);
}
#+END_SRC

#+NAME+: Run Benchmark Test with Apache Bench in cli
#+BEGIN_SRC sh
  ab -c 2 -n 2 localhost:3000/
#+END_SRC
Each fork executes in TWO seconds.

#+NAME: Code to demo parrelle processing with clusters
#+BEGIN_SRC js
// make sure the thread count is correct
process.env.UV_THREADPOOL_SIZE = 4;
const cluster = require('cluster');

if(cluster.isManager) {
  cluster.fork();
  cluster.fork();
} else {
  const express = require('express');
  const crypto = require('crypto');
  const app = express();

  app.get('/', (req, res) => {
    crypto.pbkdf2('a', 'b', 100000, 512, 'sha512', () => {
      res.send('Hi there');
    });
  });

  app.get('/fast', (req, res) => {
    res.send('This was fast!');
  });

  app.listen(3000);
}
#+END_SRC
Each fork executes in ONE second.

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646768?start=201][Course Link: Understanding Benchmark Test]]

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646768?start=540][Course Link: Benchmark issues with running many (6+) clusters]]
Continue watching from here for [[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646768?start=750][the resolution]] at around t12:30.

Basically try to match the number of CPU cores to the number of total running children.

*** Clustering with PM2 Project
:LOGBOOK:
CLOCK: [2018-05-27 Sun 13:35]--[2018-05-27 Sun 13:49] =>  0:14
:END:
PM2 - The Parallel Multithreaded Machine is a software for parallel networking of computers. 
Usually PM2 is run in remote production environments.
#+NAME: PM2 Bash Commands
#+BEGIN_SRC sh
# Start PM2, automatically generate instances
pm2 start index.js -i 0

# Kill all instances named index
pm2 delete index

# Display detailed process description
pm2 show index to 
# Display logs
pm2 logs index [--lines 1000] 

# Monitor CPU and Memory usage index
pm2 monit 
#+END_SRC
** Worker Threads
*** Webwork Threads
This isn't an amazing approach. It still depends on the number of CPU cores and the overall amount of processing power the machine running an application has.

The example will use an npm package called ~webworker-threads~.
*** Web Worker Thread Example
#+NAME: The example will use the express sample app to illustrate worker threads in action.
#+BEGIN_SRC js
// Updates to include worker example
const app = express();
const Worker = require('webworker-threads').Worker;

app.get('/', (req, res) => {
  const worker = new Worker(function () {
    this.onmessage = function () {
      let counter = 0;
      while (counter < 1e9) {
        counter++;
      }

      postMessage(counter);
    };
  });

  worker.onmessage = function (message) {
    console.log(message.data)
    res.send('' + message.data);
  };

  worker.postMessage();
});

app.get('/fast', (req, res) => {
  res.send('This was fast!');
});

app.listen(3000);
#+END_SRC

[[https://www.udemy.com/advanced-node-for-developers/learn/v4/t/lecture/9646782?start=290][Course Link: Brief description of closure scope with variable assignment.]]
* Part Three: Project Setup 
:LOGBOOK:
CLOCK: [2018-05-29 Tue 12:16]--[2018-05-29 Tue 12:33] =>  0:17
:END:
Changed branch to 'plainjane' in project.

